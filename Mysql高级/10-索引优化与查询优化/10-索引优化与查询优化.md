# 第10章索引优化与查询优化

都有哪些维度可以进行数据库调优？简言之：

- 索引失效、没有充分利用到索引一一索引建立
- 关联查询太多JOIN(设试缺陷或不得已的需求)一一SQL优化
- 服务器调优及各个参数设置（缓冲、线程数等）一一调整my.cnf
- 数据过多一一分库分表

关于数据库调优的知识点非常分散。不同的DBMS,不同的公司，不同的职位，不同的项目遇到的问题都不尽相同。这里我们分为三个章节进行细致讲解。

虽然SQL查询优化的技术有很多，但是大方向上完全可以分成**物理查询优化和逻辑查询优化**两大块。

- 物理查询优化是通过**索引和表连接**方式等技术来进行优化，这里重点需要掌握索引的使用。
- 逻辑查询优化就是通过SQL**等价变换**提升查询效率，直白一点就是说，换一种查询写法执行效率可能更高。

## 1.数据准备

学员表插50万条，班级表插1万条。

**步骤1：建表**

```mysql
CREATE TABLE `class`
(
    id        INT(11) NOT NULL AUTO_INCREMENT,
    className VARCHAR(30) DEFAULT NULL,
    address   VARCHAR(40) DEFAULT NULL,
    monitor   INT NULL,
    PRIMARY KEY (id)
)
ENGINE=INNODB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8;

CREATE TABLE `student`
(
    id INT(11) NOT NULL AUTO_INCREMENT,
    stuno INT NOT NULL,
    name VARCHAR(20)DEFAULT NULL,
    age INT(3)DEFAULT NULL,
    classId INT (11) DEFAULT NULL,
    PRIMARY KEY (id)
#CONSTRAINT fk_class_id FOREIGN KEY (classId)REFERENCES t_class ('id)
)
ENGINE=INNODB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8;
```

**步骤2：设置参数**

命令开启：允许创建函数设置：

```mysql
set global log_bin_trust_function_creators = 1 #不加g1obal只是当前窗口有效。
```

**步骤3：创建函数**

保证每条数据都不同。

```mysql
#随机产生字符串
DELIMITER //
CREATE FUNCTION rand_string(n INT) RETURNS VARCHAR(255)
BEGIN
    DECLARE chars_str VARCHAR(100) DEFAULT 'abcdefghijklmnopqrstuvwxyzABCDEFJHIJKLMNOPQRSTUVWXYZ';
    DECLARE return_str VARCHAR(255)DEFAULT '';
    DECLARE i INT DEFAULT 0;
    WHILE i < n DO
        SET return_str = CONCAT(return_str,SUBSTRING(chars_str,FLOOR(1+RAND()*52),1));
        SET i = i + 1;
    END WHILE;
    RETURN return_str;
END //
DELIMITER ;

#假如要删除
#drop function rand_string;
```

随机产生班级编号

```mysql
#用于随机产生多少到多少的编号
DELIMITER //
CREATE FUNCTION rand_num (from_num INT,to_num INT) RETURNS INT(11)
BEGIN
    DECLARE i INT DEFAULT 0;
    SET i = FLOOR(from_num +RAND()*(to_num - from_num+1));
RETURN i;
END //
DELIMITER ;
#假如要删除
#drop function rand_num;
```

**步骤4：创建存储过程**

```mysql
#创建往stu表中插入数据的存储过程
DELIMITER //
CREATE PROCEDURE insert_stu(START INT,max_num INT)
BEGIN
    DECLARE i INT DEFAULT 0;
    SET autocommit = 0;
    #设置手动提交事务
    REPEAT#循坏
        SET i = i + 1;#赋值
        INSERT INTO student (stuno,name,age,classId) VALUES
        ((START+i),rand_string(6),rand_num(1,50),rand_num(1,1000));
        UNTIL i=max_num
    END REPEAT;
    COMMIT;#提交事务
END //
DELIMITER ;
#假如要删除
#drop PROCEDURE insert_stu;
```

创建往class表中插入数据的存储过程

```mysql
#执行存储过程，往class表添加随机数据
DELIMITER //
CREATE PROCEDURE insert_class (max_num INT)
BEGIN
    DECLARE i INT DEFAULT 0;
    SET autocommit = 0;
    REPEAT
        SET i = i + 1;
        INSERT INTO class (classname,address,monitor) VALUES
        (rand_string(8),rand_string(10),rand_num(1,100000));
        UNTIL i=max_num
    END REPEAT;
    COMMIT;
END //
DELIMITER ;
#假如要删除
#drop PROCEDURE insert_class;
```

**步骤5：调用存储过程**

```mysql
#执行存储过程，往c1ass表添加1万条数据
CALL insert_class(10000);

#执行存储过程，往stu表添加50万条数据
CALL insert_stu(100000,500000);
```

**步骤6：删除某表上的索引**

创建存储过程

```mysql
DELIMITER //
CREATE PROCEDURE proc_drop_index (dbname VARCHAR(200),tablename VARCHAR(200))
BEGIN
    DECLARE done INT DEFAULT 0;
    DECLARE ct INT DEFAULT 0;
    DECLARE _index VARCHAR(200) DEFAULT '';
    DECLARE _cur CURSOR FOR SELECT index_name FROM information_schema.STATISTICS
WHERE table_schema=dbname AND table_name=tablename AND seq_in_index=1 AND index_name <>'PRIMARY';
    #每个游标必须使用不同的declare continue handler for not found set done=1来控制游标的结束
    DECLARE CONTINUE HANDLER FOR NOT FOUND set done=2;
    #若没有数据返回，程序继续，并将变量done设为2
    OPEN _cur;
    FETCH _cur INTO _index;
    WHILE _index <>'' DO
        SET @str = CONCAT('drop index',_index, ' on ', tablename);
        PREPARE sql_str FROM @str;
        EXECUTE sql_str;
        DEALLOCATE PREPARE sql_str;
        SET _index='';
        FETCH _cur INTO _index;
    END WHILE;
    CLOSE _cur;
END //
DELIMITER ;
```

执行存储过程

```mysql
CALL proc_drop_index("dbname","tablename");
```

## 2.索引失效案例

MySQL中提高性能的一个最有效的方式是对数据表设计合理的索引。索引提供了高效访问数据的方法，并且加快查询的速度，因此索引对查询的速度有着至关重要的影响。

- 使用索可以快速地定位表中的某条记录，从而提高数据库查询的速度，提高数据库的性能。
- 如果查询时没有使用索引，查询语句就会扫描表中的所有记录。在数据量大的情况下，这样查询的速度会很慢。

大多数情况下都（默认）采用B+树来构建索引。只是空间列类型的索引使用R-树，并且MEMORY表还支持hash索引。

其实，用不用索引，最终都是优化器说了算。优化器是基于什么的优化器？基于cost开销(CostBasetOptimizer),它不是基于规则(Rule-BasedOptimizer),也不是基于语义。怎么样开销小就怎么来。另外，**SQL语句是否使用索引，跟数据库版本、数据量、数据选择度都有关系。**

### 2.1 全值匹配我最爱

系统中经常出现的sql语句如下：

```mysql
EXPLAIN SELECT SQL_NO_CACHE FROM student WHERE age=30;
EXPLAIN SELECT SQL_NO_CACHE FROM student WHERE age=30 and classId=4;
EXPLAIN SELECT SQL_NO_CACHE FROM student WHERE age=30 and classId=4 AND name 'abcd';
```

建立索引

```mysql
CREATE INDEX idx_age ON student(age);
CREATE INDEX idx_age_classid ON student(age,classId);
CREATE INDEX idx_age_classid_name ON student(age,classId,name);
```

可以看到，索引帮助我们极大的提高了查询效率。

### 2.2 最佳左前缀法则

在MySQL建立联合索引时会遵守最佳左前缀匹配原则，即最左优先，在检索数据时从联合索引的最左边开始匹配。

```mysql
EXPLAIN SELECT SQL_NO_CACHE FROM student WHERE student.age=30 AND student.name ='abcd';

EXPLAIN SELECT SQL_NO_CACHE FROM student WHERE student.classid=1 AND student.name = 'abcd';
```

**索引idx_age_classid_name还能否正常使用？**

```mysql
EXPLAIN SELECT SQL_NO_CACHE FROM student WHERE classid=4 AND student.age=30 AND student.name = 'abcd';
```

结论：MySQL可以为多个字段创建索引，一个索引可以包括16个字段。对于多列索引，**过滤条件要使用索引必须按照索引建立时的顺序，依次满足，一旦跳过某个字段，索引后面的字段都无法被使用。**如果查询条件中没有使用这些字段中第1个字段时，多列（或联合）索引不会被使用。

> **拓展：Alibaba《Java开发手册》**
> 索引文件具有B-Tree的最左前缀匹配特性，如果左边的值未确定，那么无法使用此索引。

### 2.3 主键插入顺序

对于一个使用InnoDB存储引擎的表来说，在我们没有显式的创建索引时，表中的数据实际上都是存储在聚簇索引的叶子节点的。而记录又是存储在数据页中的，数据页和记录又是按照记录主键值从小到大的顺序进行排序，所以如果我们插入的记录的主键值是依次增大的话，那我们每插满个数据页就换到下一个数据页继续插，而如果我们插入的主键值忽大忽小的话，就比较麻烦了，假设某个数据页存储的记录已经满了，它存储的主键值在1~180之间：

![image-20220329143754623](https://zhangyuyetypora.oss-cn-guangzhou.aliyuncs.com/typora-user-images/image-20220329143754623.png)

如果此时再插入一条主键值为9的记录，那它插入的位置就如下图：

![image-20220329143837034](https://zhangyuyetypora.oss-cn-guangzhou.aliyuncs.com/typora-user-images/image-20220329143837034.png)

可这个数据页已经满了，再插进来咋办呢？我们需要把当前页面分裂成两个页面，把本页中的一些记录移动到新创建的这个页中。页面分裂和记录移位意味着什么？意味着：性能损耗！所以如果我们想尽量避免这样无谓的性能损耗，最好让插入的记录的主键值依次递增，这样就不会发生这样的性能损耗了。所以我们建议：让主键具有AUTO_INCREMENT,让存储引擎自己为表生成主键，而不是我们手动插入，

我们自定义的主键列id拥有AUTO_INCREMENT属性，在插入记录时存储引擎会自动为我们填入自增的主键值。这样的主键占用空间小，顺序写入，减少页分裂。

### 2.4 计算、函数、类型转换（自动或手动）导致索引失效

### 2.5 类型转换导致索引失效

### 2.6 范围条件右边的列索引失效

> 应用开发中范围查询，例如：金额查询，日期查询往往都是范围查询。应将查询条件放置where语句最后。
>
> (创建的联合索引中，务必把范围涉及到的字段写在最后)

### 2.7 不等于(!=或者<>)索引失效

### 2.8 is null可以使用索引，is not null无法使用索引

### 2.9 like以通配符%开头索引失效

> 拓展：Alibaba《Java开发手册》
>
> 【强制】页面搜索严芽左模糊或者全模糊，如果需要请走搜索引擎来解决。

### 2.10 OR前后存在非索引的列，索引失效

在WHERE子句中，如果在OR前的条件列进行了索引，而在OR后的条件列没有进行索引，那么索引会失效。也就是说，**OR前后的两个条件中的列都是索引时，查询中才使用索引。**

因为O的含义是两个只要满足一个即可，因此只有一个条件列进行了索引是没有意义的，只要有条件列没有进行索引，就会进行全表扫描，因此索引的条件列也会失效。

### 2.11 数据库和表的字符集统一使用utf8mb4

统一使用utf8b4(5.5.3版本以上支持谦容性更好，统一字符集可以避免由于字符集转换产生的乱码。不同的字符集进行比较前需要进行转换会造成索引失效。

### 2.12 练习及一般性建议

一般性建议:

- 对于单列索引，尽量选择针对当前query过滤性更好的索引
- 在选择组合索引的时候，当前queryt中过滤性最好的字段在索引字段顺序中，位置越靠前越好。
- 在选择组合索引的时候，尽量选择能够包含当前query中的where-子句中更多字段的索引。
- 在选择组合索引的时候，如果某个字段可能出现范围查询时，尽量把这个字段放在索引次序的最后面。

**总之，书写SQL语句时，尽量避免造成索引失效的情况。**

## 3.关联查询优化

### 3.1 数据准备

```mysql
create database indexyouhuo;

use indexyouhuo;


#分类
CREATE TABLE IF NOT EXISTS type
(
    id   INT(10) UNSIGNED NOT NULL AUTO_INCREMENT,
    card INT(10) UNSIGNED NOT NULL,
    PRIMARY KEY (id)
);
#图书
CREATE TABLE IF NOT EXISTS Sbook
(
    bookid INT(10) UNSIGNED NOT NULL AUTO_INCREMENT,
    card   INT(10) UNSIGNED NOT NULL,
    PRIMARY KEY (bookid)
);
#向分类表中添加20条记录
INSERT INTO TYPE (card) VALUES (FLOOR(1 + (RAND() * 20)));
INSERT INTO TYPE (card) VALUES (FLOOR(1 + (RAND() * 20)));
INSERT INTO TYPE (card) VALUES (FLOOR(1 + (RAND() * 20)));
INSERT INTO TYPE (card) VALUES (FLOOR(1 + (RAND() * 20)));
INSERT INTO TYPE (card) VALUES (FLOOR(1 + (RAND() * 20)));
INSERT INTO TYPE (card) VALUES (FLOOR(1 + (RAND() * 20)));
INSERT INTO TYPE (card) VALUES (FLOOR(1 + (RAND() * 20)));
INSERT INTO TYPE (card) VALUES (FLOOR(1 + (RAND() * 20)));
INSERT INTO TYPE (card) VALUES (FLOOR(1 + (RAND() * 20)));
INSERT INTO TYPE (card) VALUES (FLOOR(1 + (RAND() * 20)));
INSERT INTO TYPE (card) VALUES (FLOOR(1 + (RAND() * 20)));
INSERT INTO TYPE (card) VALUES (FLOOR(1 + (RAND() * 20)));
INSERT INTO TYPE (card) VALUES (FLOOR(1 + (RAND() * 20)));
INSERT INTO TYPE (card) VALUES (FLOOR(1 + (RAND() * 20)));
INSERT INTO TYPE (card) VALUES (FLOOR(1 + (RAND() * 20)));
INSERT INTO TYPE (card) VALUES (FLOOR(1 + (RAND() * 20)));
INSERT INTO TYPE (card) VALUES (FLOOR(1 + (RAND() * 20)));
INSERT INTO TYPE (card) VALUES (FLOOR(1 + (RAND() * 20)));
INSERT INTO TYPE (card) VALUES (FLOOR(1 + (RAND() * 20)));
INSERT INTO TYPE (card) VALUES (FLOOR(1 + (RAND() * 20)));

#向图书表中添加20条记录
INSERT INTO sbook(card) VALUES (FLOOR (1 + (RAND() * 20)));
INSERT INTO sbook(card) VALUES (FLOOR (1 + (RAND() * 20)));
INSERT INTO sbook(card) VALUES (FLOOR (1 + (RAND() * 20)));
INSERT INTO sbook(card) VALUES (FLOOR (1 + (RAND() * 20)));
INSERT INTO sbook(card) VALUES (FLOOR (1 + (RAND() * 20)));
INSERT INTO sbook(card) VALUES (FLOOR (1 + (RAND() * 20)));
INSERT INTO sbook(card) VALUES (FLOOR (1 + (RAND() * 20)));
INSERT INTO sbook(card) VALUES (FLOOR (1 + (RAND() * 20)));
INSERT INTO sbook(card) VALUES (FLOOR (1 + (RAND() * 20)));
INSERT INTO sbook(card) VALUES (FLOOR (1 + (RAND() * 20)));
INSERT INTO sbook(card) VALUES (FLOOR (1 + (RAND() * 20)));
INSERT INTO sbook(card) VALUES (FLOOR (1 + (RAND() * 20)));
INSERT INTO sbook(card) VALUES (FLOOR (1 + (RAND() * 20)));
INSERT INTO sbook(card) VALUES (FLOOR (1 + (RAND() * 20)));
INSERT INTO sbook(card) VALUES (FLOOR (1 + (RAND() * 20)));
INSERT INTO sbook(card) VALUES (FLOOR (1 + (RAND() * 20)));
INSERT INTO sbook(card) VALUES (FLOOR (1 + (RAND() * 20)));
INSERT INTO sbook(card) VALUES (FLOOR (1 + (RAND() * 20)));
INSERT INTO sbook(card) VALUES (FLOOR (1 + (RAND() * 20)));
INSERT INTO sbook(card) VALUES (FLOOR (1 + (RAND() * 20)));
```

### 3.2 采用左外连接

```mysql
EXPLAIN SELECT SQL_NO_CACHE * FROM `type` LEFT JOIN Sbook ON type.card = Sbook.card;
```

![image-20220330123033278](https://zhangyuyetypora.oss-cn-guangzhou.aliyuncs.com/typora-user-images/image-20220330123033278.png)

```mysql
CREATE INDEX idex_book ON Sbook(card);
CREATE INDEX idex_type ON type(card);

EXPLAIN SELECT SQL_NO_CACHE * FROM `type` LEFT JOIN Sbook ON type.card = Sbook.card;
```

![image-20220330123226464](https://zhangyuyetypora.oss-cn-guangzhou.aliyuncs.com/typora-user-images/image-20220330123226464.png)

### 3.3 采用内连接

```mysql
DROP INDEX idex_book ON Sbook;
DROP INDEX idex_type ON type;

EXPLAIN SELECT SQL_NO_CACHE * FROM type INNER JOIN sbook ON type.card = sbook.card;
```

![image-20220330123720450](https://zhangyuyetypora.oss-cn-guangzhou.aliyuncs.com/typora-user-images/image-20220330123720450.png)

```mysql
CREATE INDEX idex_book ON Sbook(card);
CREATE INDEX idex_type ON type(card);

EXPLAIN SELECT SQL_NO_CACHE * FROM type INNER JOIN sbook ON type.card = sbook.card;
```

![image-20220330123809345](https://zhangyuyetypora.oss-cn-guangzhou.aliyuncs.com/typora-user-images/image-20220330123809345.png)

结论：对于内连接来讲，如果表的连接条件中只能有一个字段有索引，则有索引的字段所在的表会被作为被驱动表

结论：对于内连接来说，在两个表的连接条件都存在索引的情况下，会选择小表作为驱动表。“小表驱动大表"

### 3.4 join语句原理

join方式连接多个表，本质就是各个表之间数据的循环匹配。MySQL5.5版本之前，MySQL只支持一种表间关联方式，就是嵌套循环(Nested Loop Join)。如果关联表的数据量很大，则join关联的执行时间会非常长。在MySQL5.5以后的版本中，MySQL通过引入BNLJ算法来优化嵌套执行。

#### 1.驱动表和被驱动表

驱动表就是主表，被驱动表就是从表、非驱动表。

- **对于内连接来说：**

```mysql
SELECT FROM A JOIN B ON ...
```

A一定是驱动表吗？不一定，优化器会根据你查询语句做优化，决定先查哪张表。先查询的那张表就是驱动表反之就是被驱动表。通过explain关键字可以查看。

- **对于外连接来说：**

```mysql
SELECT FROM A LEFT JOIN B ON ...

#或

SELECT*FROM B RIGHT JOIN A ON ···
```

通常，大家会认为A就是驱动表，B就是被驱动表。但也未必。测试如下： 

```mysql
CREATE TABLE a(f1 INT,f2 INT,INDEX(f1)) ENGINE=INNODB;

CREATE TABLE b(f1 INT,f2 INT) ENGINE=INNODB;

INSERT INTO a VALUES (1,1),(2,2),(3,3),(4,4),(5,5),(6,6);
INSERT INTO b VALUES (3,3),(4,4),(5,5),(6,6),(7,7),(8,8);

#测试1
EXPLAIN SELECT * FROM a LEFT JOIN b ON (a.f1=b.f1) WHERE (a.f2=b.f2);

#测试2
EXPLAIN SELECT * FROM a LEFT JOIN b ON (a.f1=b.f1) AND (a.f2=b.f2);
```

#### 2. Simple Nested-Loop Join(简单嵌套循环连接)

算法相当简单，从表A中取出一条数据1，遍历表B,将匹配到的数据放到result.以此类推，驱动表A中的每一条记录与被驱动表B的记录进行判断：

![image-20220330125046394](https://zhangyuyetypora.oss-cn-guangzhou.aliyuncs.com/typora-user-images/image-20220330125046394.png)

可以看到这种方式效率是非常低的，以上述表A数据100条，表B数据1000条计算，则A*B=10万次。开销统计如下：

| 开销统计           | SNLJ  |
| ------------------ | ----- |
| 外表扫描次数：     | 1     |
| 内表扫描次数：     | A     |
| 读取记录数：       | A+B*A |
| JOIN比较次数：     | B*A   |
| 回表读取记录次数： | 0     |

当然nysql肯定不会这么粗暴的去进行表的连接，所以就出现了后面的两种对Nested-Loop Join优化算法。

#### 3. Index Nested-Loop Join(索引嵌套循环连接)

Index Nested-Loop Join其优化的思路主要是为了**减少内层表数据的匹配次数**，所以要求被驱动表上必须有索引才行。通过外层表匹配条件直接与内层表索引进行匹配，避免和内层表的每条记录去进行比较，这样极大的减少了对内层表的匹配次数。

![image-20220330125429613](https://zhangyuyetypora.oss-cn-guangzhou.aliyuncs.com/typora-user-images/image-20220330125429613.png)

驱动表中的每条记录通过被驱动表的索引进行访问，因为索引查询的成本是比较固定的，故mysql优化器都倾向于使用记录数少的表作为驱动表（外表）。

| 开销统计           | SNLJ  | INLJ                  |
| ------------------ | ----- | --------------------- |
| 外表扫描次数：     | 1     | 1                     |
| 内表扫描次数：     | A     | 0                     |
| 读取记录数：       | A+B*A | A+B(match)            |
| JOIN比较次数：     | B*A   | A*Index(Height)       |
| 回表读取记录次数： | 0     | B(match)(if possible) |

如果被驱动表加索引，效率是非常高的，但如果索引不是主键索引，所以还得进行一次回表查询。相比，被驱动表的索引是主键索引，效率会更高。

#### 4. Block Nested-Loop Join(块嵌套循环连接)

如果存在索引，那么会使用index的方式进行join,如果join的列没有索引，被驱动表要扫描的次数太多了。每次访问被驱动表，其表中的记录都会被加载到内存中，然后再从驱动表中取一条与其匹配，匹配结束后清除内存，然后再从驱动表中加载一条记录，然后把被驱动表的记录在加载到内存匹配，这样周而复始，大大增加了I/O的次数。为了减少被驱动表的I/O次数，就出现了Block Nested-Loop Join的方式。

不再是逐条获取驱动表的数据，而是一块一块的获取，引入了**join buffer缓冲区**，将驱动表join相关的部分数据列（大小受join buffer的限制）缓存到join buffer中，然后全表扫描被驱动表，被驱动表的每一条记录一次性和join buffer中的所有驱动表记录进行匹配（内存中操作），将简单嵌套循环中的多次比较合并成一次，降低了被驱动表的访问频率。

> 注意：
>
> 这里缓存的不只是关联表的列，select后面的列t也会缓存起来。
>
> 在一个有N个join关联的sql中会分配N-1个join buffer。所以查询的时候尽量减少不必要的字段，可以让join
> buffer中可以存放更多的列。

![image-20220330130011189](https://zhangyuyetypora.oss-cn-guangzhou.aliyuncs.com/typora-user-images/image-20220330130011189.png)

| 开销统计           | SNLJ  | INLJ                  | BNLJ                                          |
| ------------------ | ----- | --------------------- | --------------------------------------------- |
| 外表扫描次数：     | 1     | 1                     | 1                                             |
| 内表扫描次数：     | A     | 0                     | A * used_column_size/join_buffer_size+1       |
| 读取记录数：       | A+B*A | A+B(match)            | A+B * (A * used_column_size/join_buffer_size) |
| JOIN比较次数：     | B*A   | A*Index(Height)       | B*A                                           |
| 回表读取记录次数： | 0     | B(match)(if possible) | 0                                             |

参数设置：

- block_nested_loop

通过`show variables like '%optimizer_switch%'`查看block_nested_loop状态。默认是开启的。

- join_buffer_size

驱动表能不能一次加载完，要看join buffer能不能存储所有的数据，默认情况下join_buffer_size=256k。

```mysql
show variables like '%join_buffer%';

+------------------+--------+
| Variable_name    | Value  |
+------------------+--------+
| join_buffer_size | 262144 |
+------------------+--------+
1 row in set, 1 warning (0.00 sec)
```

join_buffer_.size的最大值在32位系统可以申请4G,而在64位操做系统下可以申请大于4G的Join Buffer?空间(64位Windows除外，其大值会被截断为4GB并发出警告)。

#### 5. Join小结

1. 整体效率比较：INLJ>BNLJ>SNLJ
2. 永远用小结果集驱动大结果集（其本质就是减少外层循环的数据数量）(小的度量单位指的是表行数*每行大小)
3. 为被驱动表匹配的条件增加索引（减少内层表的循环匹配次数）
4. 增大join_buffer_size的大小（一次缓存的数据越多，那么内层包的扫表次数就越少）
5. 减少驱动表不必要的字段查询（字段越少，join buffer所缓存的数据就越多）

#### 6. Hash Join

**从MySQLl的8.0.20版本开始将废弃BNLJ,因为从MySQL8.0.18版本开始就加入了hash join默认都会使用hash join**

- Nested Loop:
	对于被连接的数据子集较小的情况，Nested Loop是个较好的选择。
- Hash Join是做**大数据集连接**时的常用方式，优化器使用两个表中较小（相对较小）的表利用Join Key在内存中建立**散列表**，然后扫描较大的表并探测散列表，找出与Hash表匹配的行。
	- 这种方式适用于较小的表完全可以放于内存中的情况，这样总成本就是访问两个表的成本之和。
	- 在表很大的情况下并不能完全放入内存，这时优化器会将它分割成若干不同的分区，不能放入内存的部分就把该分区写入磁盘的临时段，此时要求有较大的临时段从而尽量提高/O的性能。
	- 它能够很好的工作于没有索引的大表和并行查询的环境中，并提供最好的性能。大多数人都说它是Join的重型升降机。Hash Join只能应用于等值连接（如WHERE A.COL1=B.COL2),这是由Hash的特点决定的。

| 类别     | Nested Loop                                                  | Hash Join                                                    |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 使用条件 | 任何条件                                                     | 等值连接(=)<br/><br/><br/>                                   |
| 相关资源 | CPU、磁盘I/O                                                 | 内存、临时空间                                               |
| 特点     | 当有高选择性索引或进行限制性搜索时效率比较高，能够快速返回第一次的搜索结果。 | 当缺乏索引或者索引条件模糊时，Hash Join比Nested Loop有效。在数据仓库环境下，如果表的纪录数多，效率高。 |
| 缺点     | 当索引丢失或者查询条件限制不够时，效率很低；当表的纪录数多时，效率低。 | 为建立哈希表，需腰大量内存。第一次的结果返回较慢。           |



## 4.子查询优化

MySQL从4.1版本开始支持子查询，使用子查询可以进行SELECT语句的嵌套查询，即一个SELECT查询的结果作为另一个SELECT语句的条件。**子查询可以一次性完成很多逻辑上需要多个步骤才能完成的SQL操作。**

**子查询是MySQL的一项重要的功能，可以帮助我们通过一个SQL语句实现比较复杂的查询。但是，子查询的执**
**行效率不高。**原因：

①执行子查询时，MySQL需要为内层查询语句的查询结果**建立一个临时表**，然后外层查询语句从临时表中查询记录。查询完毕后，再**撤销这些临时表**。这样会消耗过多的CPU和IO资源，产生大量的慢查询。

②子查询的结果集存储的临时表，不论是内存临时表还是磁盘临时表都**不会存在索引**，所以查询性能会受到一定的影响。

③对于返回结果集比较大的子查询，其对查询性能的影响也就越大。

**在MySQLI中，可以使用连接(JOIN)查询来替代子查询。**连接查询**不需要建立临时表**，其速度比**子查询要快**，如果查询中使用索引的话，性能就会更好。

举例1：查询学生表中是班长的学生信息

- 使用子查询

```mysql
#创建班级表中班长的索引
CREATE INDEX idx_monitor ON class (monitor);

EXPLAIN
SELECT *
FROM student stu1
WHERE stu1.`stuno` IN
(SELECT monitor FROM class c WHERE monitor IS NOT NULL);
```

- 推荐：使用多表查询

```mysql
EXPLAIN SELECT stu1.* FROM student stu1 JOIN class c ON stu1.`stuno` = c.`monitor` WHERE c.monitor IS NOT NULL;
```

> 结论：尽量不要使用NOT IN或者NOT EXISTS,用LEFT JOIN XXX ON XX WHERE XXX IS NULL替代

## 5.排序优化

### 5.1排序优化

问题：在WHERE条件字段上加索引，但是为什么在ORDER BY字段上还要加索引呢？

回答：

在MySQL中，支持两种排序方式，分别是FileSort和Index排序。

- ldex排序中，索引可以保证数据的有序性，不需要再进行排序，**效率更高。**
- FileSort排序则一般在**内存中**进行排序，占用**CPU较多**。如果待排结果较大，会产生临时文件I/O到磁盘进行排序的情况，效率较低。

优化建议：

1. SQL中，可以在WHERE子句和ORDER BY子句中使用索引，目的是在WHERE子句中**避免全表扫描**，在ORDER BY子句**避免使用FileSort排序**。当然，某些情况下全表扫描，或者FileSort排序不一定比索慢。但总的来说，我们还是要避免，以提高查询效率。

2. 尽量使用Index完成ORDER BY排序。如果WHERE和ORDER BY后面是相同的列就使用单索引列；如果不同就使用联合索引。

3. 无法使用Index时，需要对FileSort方式进行调优。

### 5.2测试

删除student表和class表中已创建的索引。

```mysql
#方式1：
DROP INDEX idx_monitor ON class;
DROP INDEX idx_cid ON student;
DROP INDEX idx_age ON student;
DROP INDEX idx_name ON student;
DROP INDEX idx_age_name_classid ON student;
DROP INDEX idx_age_classid_name ON student;
#方式2：
call proc_drop_index('atguigudb2','student');
```

**过程一：**

```mysql
EXPLAIN SELECT SQL_NO_CACHE * FROM student ORDER BY age,classId;

EXPLAIN SELECT SQL_NO_CACHE * FROM student ORDER BY age,classId LIMIT 10;
```

**过程二：order by时不limit,索引失效**

```mysql
#创建索引
CREATE INDEX idx_age_classid_name ON student (age,classid,NAME);

#不限制，索引失效
EXPLAIN SELECT SQL_NO_CACHE * FROM student ORDER BY age,classid;

#增加limit过滤条件，使用上索引了。
EXPLAIN SELECT SQL_NO_CACHE * FROM student ORDER BY age,classid LIMIT 10;
```

**过程三：order by时顺序错误，索引失效**

```mysql
#创建索引age,classid,stuno
CREATE INDEX idx_age_classid_stuno ON student (age,classid,stuno);

#以下哪些索引失效？
EXPLAIN SELECT * FROM student ORDER BY classid LIMIT 10;

EXPLAIN SELECT * FROM student ORDER BY classid,NAME LIMIT 10;

EXPLAIN SELECT * FROM student ORDER BY age,classid,stuno LIMIT 10;

EXPLAIN SELECT * FROM student ORDER BY age,classid LIMIT 10;

EXPLAIN SELECT * FROM student ORDER BY age LIMIT 10;
```

**过程四：order by时规侧不一致，索引失效（顺序错，不索引；方向反，不索引)**

```mysql
EXPLAIN SELECT * FROM student ORDER BY age DESC,classid ASC LIMIT 10;

EXPLAIN SELECT * FROM student ORDER BY classid DESC,NAME DESC LIMIT 10;

EXPLAIN SELECT * FROM student ORDER BY age ASC,classid DESC LIMIT 10;

EXPLAIN SELECT * FROM student ORDER BY age DESC,classid DESC LIMIT 10;
```

> 结论：ORDER BY子句，尽量使用Index方式排序，避免使用FileSort方式排序

**过程五：无过滤，不索引**

```mysql
EXPLAIN SELECT * FROM student WHERE age=45 ORDER BY classid;

EXPLAIN SELECT * FROM student WHERE age=45 ORDER BY classid,name;

EXPLAIN SELECT * FROM student WHERE classid=45 order by age;

EXPLAIN SELECT * FROM student WHERE classid=45 order by age limit 10;
```

小结:

```mysql
INDEX a_b_c(a,b,c)

order by 能使用索引最左前缀
- ORDER BY a
- ORDER BY a,b
- ORDER BY a,b,c
- ORDER BY a DESC,b DESC,c DESC

如果WHERE使用索引的最左前缀定义为常量，则order by能使用索引
- WHERE a const ORDER BY b,c
- WHERE a const AND b const ORDER BY c
- WHERE a const ORDER BY b,c
- WHERE a const AND b const ORDER BY b,c

不能使用索引进行排序
- ORDER BY a ASC,b DESC,c DESC /*排序不一致*/
- WHERE g=const ORDER BY b,C   /*丢失a索引*/
- WHERE a=const ORDER BY c     /*丢失b索引*/
- WHERE a=const ORDER BY a,d   /*d不是索引的一部分*/
- WHERE a in(.·.) ORDER BY b,c /*对于排序来说，多个相等条件也是范围查询*/
```

### 5.3案例实战

ORDER BY-子句，尽量使用Index方式排序，避免使用FileSort方式排序。

执行案例前先清除student.上的索引，只留主键：

```mysql
DROP INDEX idx_age ON student;
DROP INDEX idx_age_classid_stuno ON student;
DROP INDEX idx_age_classid_name ON student;

#或者
call proc_drop_index('indexyouhuo','student');
```

**场景：查询年龄为30岁的，且学生编号小于101000的学生，按用户名称排序**

```mysql
EXPLAIN SELECT SQL_NO_CACHE FROM student WHERE age 30 AND stuno <101000 ORDER BY NAME
```

![image-20220330140903484](https://zhangyuyetypora.oss-cn-guangzhou.aliyuncs.com/typora-user-images/image-20220330140903484.png)

方案一：为了去掉filesort我们可以把索引建成

```mysql
CREATE INDEX idx_age_name ON student(age,name);

EXPLAIN SELECT SQL_NO_CACHE * FROM student WHERE age = 30 AND stuno <101000 ORDER BY NAME;
```

方案二：尽量让wherel的过滤条件和排序使用上索引

```mysql
CREATE INDEX idx_age_stuono_name ON student(age,stuno,name);

EXPLAIN SELECT SQL_NO_CACHE * FROM student WHERE age = 30 AND stuno <101000 ORDER BY NAME;
```

结果竟然有filesort的sal运行速度，超过了已经优化掉filesort的sq1,而且快了很多，几乎一瞬间就出现了结果。

原因：

所有的排序都是在条件过滤之后才执行的。所以，如果条件过滤掉大部分数据的话，剩下几百几干条数据进行排序其实并不是很消耗性能，即使索引优化了排序，但实际提升性能很有限。相对的stuo<101000这个条件，如果没有用到索引的话，要对几万条的数据进行扫描，这是非常消耗性能的，所以索引放在这个字段上性价比最高，是最优选择

> 结论：
>
> 1.两个索引同时存在，mysql自动选择最优的方案。（对于这个例子，mysqli选择idx_age_stuno_name)。但是，随着数据量的变化，选择的索引也会随之变化的。
>
> 2.**当【范围条件】和【group by或者order by.】的字段出现二选一时，优先观察条件字段的过滤数量，如果过滤的数据足够多，而需要排序的数据并不多时，优先把索引放在范围字段上。反之，亦然。**

### 5.4 filesort算法：双路排序和单路排序

排序的字段若如果不在索引列上，则filesort会有两种算法：**双路排序和单路排序**

**双路排序（慢）**

- MySQL4.1之前是使用双路排序，字面意思就是两次扫描磁盘，最终得到数据，读取行指针和order by?列，对他们进行排序，然后扫描已经排序好的列表，按照列表中的值重新从列表中读取对应的数据输出
- 从磁盘取排序字段，在buffer进行排序，再从磁盘取其他字段。

取一批数据，要对磁盘进行两次扫描，众所周知，IO是很耗时的，所以在mysql4.1之后，出现了第二种改进的算法，就是单路排序。

**单路排序（快）**

从磁盘读取查询需要的所有列，按照order by列在buffer对它们进行排序，然后扫描排序后的列表进行输出，它的效率更快一些，避免了第二次读取数据。并且把随机O变成了顺序0，但是它会使用更多的空间，因为它把每一行都保存在内存中了。

**结论及引申出的问题**

- 由于单路是后出的，总体而言好过双路
- 但是用单路有问题
	- 在sort_buffer中，单路比多路要多占用很多空间，因为单路是把所有字段都取出，所以有可能取出的数据的总大小超出了sort_buffer的容量，导致每次只能取sort_buffer容量大小的数据，进行排序（创建tmp文件，多路合并)，排完再取sort_buffer容量大小，再排..…从而多次l/O。
	- 单路本来想省一次I/O操作，反而导致了大量的I/O操作，反而得不偿失。

**优化策略**

**1.尝试提高sort_buffer_size**

- 不管用哪种算法，提高这个参数都会提高效率，要根据系统的能力去提高，因为这个参数是针对每个进程(connection)的1M-8M之间调整。MySQL5.7,InnoDB存储引擎默认值是1048576字节，1MB。

	```mysql
	SHOW VARIABLES LIKE '%sort_buffer_size%';
	```

**2.尝试提高max_length_for_sort_data**

- 提高这个参数，会增加用改进算法的概率。

	```mysql
	SHOW VARIABLES LIKE '%max_length_for_sort_data%';
	```

- 但是如果设的太高，数据总容量超出sort_buffer_.size的概率就增大，明显症状是高的磁盘l/O活动和低的处理器使用率。如果需要返回的列的总长度大于max_length_for_sort_data,使用双路算法，否侧使用单路算法。1024-8192字节之间调整

**3.Order by时select * 是一个大忌。最好只Query需要的字段。**原因：

- 当Query的字段大小总和小于max_length_for-sort_data,而且排序字段不是TEXTBLOB类型时，会用改进后的算法一一单路排序，否则用老算法一一多路排序。
- 两种算法的数据都有可能超出sort_buffer_size的容量，超出之后，会创建tmp文件进行合并排序，导致多次l/O,但是用单路排序算法的风险会更大一些，所以要提高sort_buffer_size。

## 6. GROUP BY优化

- group by使用索的原测几乎跟order by-一致，group by即使没有过滤条件用到索引，也可以直接使用索引。
- group by先排序再分组，遵照索引建的最佳左前缀法则
- 当无法使用索引列，增大max_length_for_-sort-data和sort_buffer_size参数的设置
- where效率高于having,能写在where限定的条件就不要写在having中了
- 减少使用order by,和业务沟通能不排序就不排序，或将排序放到程序端去做。Order by、group by、distinct
- 这些语句较为耗费CPU,数据库的CPU资源是极其宝贵的。
- 包含了order by、.group by、.distinct这些查询的语句，where条件过滤出来的结果集请保持在1000行以内，否则SQL会很慢。

## 7.优化分页查询

一般分页查询时，通过创建覆盖索能够比较好地提高性能。一个常见又非常头疼的问题就是limit 2000000,10,此时需要MySQL排序前2000010记录，仅仅返回2000000-2000010的记录，其他记录丢弃，查询排序的代价非常大。

```mysql
EXPLAIN SELECT FROM student LIMIT 2000000,10;
```

优化思路一

在索引上完成排序分页操作，最后根据主键关联回原表查询所需要的其他列内容。

```mysql
EXPLAIN SELECT * FROM student t,(SELECT id FROM student ORDER BY id LIMIT 2000000,10) a WHERE t.id a.id;
```

优化思路二

该方案适用于主键自增的表，可以把Limit查询转换成某个位置的查询。

```mysql
EXPLAIN SELECT * FROM student WHERE id > 1000000 LIMIT 10;
```



## 8.优先考虑覆盖索引

### 8.1什么是覆盖索引？

**理解方式一：**索引是高效找到行的一个方法，但是一般数据库也能使用索引找到一个列的数据，因此它不必读取整个行。毕竟索引叶子节点存储了它们索引的数据；当能通过读取索引就可以得到想要的数据，那就不需要读取行了。**一个索引包含了满足查询结果的数据就叫做覆盖索引。**

**理解方式二：**非聚簇复合索引的一种形式，它包括在查询里的SELECT、JOIN和WHERE子句用到的所有列**(即建索引的字段正好是覆盖查询条件中所涉及的字段）**

**简单说就是, 索引列+主键 包含 SELECT 到 FROM之间查询的列。**

### 8.2覆盖索引的利弊

**好处：**

**1.避免Innodb表进行索引的二次查询（回表）**

Innodb是以聚集索引的顺序来存储的，对于Innodb来说，二级索引在叶子节点中所保存的是行的主键信息，如果是用二级索引查询数据，在查找到相应的键值后，还需通过主键进行二次查询才能获取我们真实所需要的数据。

在覆盖索引中，二级索引的键值中可以获取所要的数据，**，避免了对主键的二次查询， 减少了IO操作，提升了查询效率。**

**2.可以把随机IO变成顺序IO加快查询效率**

由于覆盖索引是按键值的顺序存储的，对于IO密集型的范围查找来说，对比随机从磁盘读取每一行的数据IO要少的多，因此利用覆盖索引在访问时也可以把磁盘的 **随机读取的IO** 转变成索引查找的 **顺序IO** 。

**由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。**

**弊端:**

**索引字段的维护总是有代价的。**因此，在建立冗余索引来支持覆盖索时就需要权衡考虑了。这是业务DBA,或者称为业务数据架构师的工作。

## 9.如何给字符串添加索引

### 9.1 前缀索引

### 9.2 前缀索引对覆盖索引的影响

### 9.3 拓展内容

> 从查询效率上看，使用hash字段方式的查询性能相对更稳定一些。因为crc32算出来的值虽然有冲突的概率，但是概率非常小，可以认为每次查询的平均扫描行数接近1。而倒序存储方式毕竟还是用的前缀索引的方式，也就是说还是会增加扫描行数。

## 10.索引下推

### 10.1 使用前后的扫描过程

Index Condition Pushdown(lCP)是MySQL5.6中新特性，是一种在存储引擎层使用索引l过滤数据的优化方式。

- 如果没有ICP,存储引擎会遍历索引以定位基表中的行，并将它们返回给MySQL服务器，由MySQL服务器评估WHERE后面的条件是否保留行。
- 启用ICP后，如果部分WHERE条件可以仅使用索引中的列进行筛选，则MySQL服务器会把这部分WHERE条件放到存储引擎筛选。然后，存储引擎通过使用索引条目来筛选数据，并且只有在满足这一条件时才从表中读取行。
	- 好处：ICP可以减少存储引擎必须访问基表的次数和MySQL服务器必须访问存储引擎的次数。
	- 但是，ICP的加速效果取决于在存储引擎内通过ICP筛选掉的数据的比例。

### 10.2 ICP的开启/关闭

- 默认情况下启用索引条件下推。可以通过设置系统变量optimizer._switch控制：index_condition_pushdown

	```mysql
	#打开索引下推
	SET optimizer_switch ='index_condition_pushdown=on';
	#关闭索引下推
	SET optimizer_switch ='index_condition_pushdown=off';
	```

- 当使用索引条件下推时，EXPLAIN语句输出结果中Extra列内容显示为Using index condition。

### 10.3 ICP使用案例

建表

```mysql
CREATE TABLE people
(
    `id`        INT NOT NULL AUTO_INCREMENT,
    `zipcode`   VARCHAR(20) COLLATE utf8_bin DEFAULT NULL,
    `firstname` VARCHAR(20) COLLATE utf8_bin DEFAULT NULL,
    `lastname`  VARCHAR(20) COLLATE utf8_bin DEFAULT NULL,
    `address`   VARCHAR(50) COLLATE utf8_bin DEFAULT NULL,
    PRIMARY KEY (id),
    KEY `zip_last_first` (zipcode, lastname, firstname)
) ENGINE=InnoDB AUTO_INCREMENT=5 DEFAULT CHARSET=utf8mb3 COLLATE=utf8_bin;
```

插入数据

```mysql
INSERT INTO people VALUES
('1','000001','三','张','北京市'),
('2','000002','四','李','南京市'),
('3','000003','五','王','上海市'),
('4','000001','六','赵','天津市');
```

为该表定义联合索引zip_last_first(zipcode,lastname,firstname)。如果我们知道了一个人的邮编，但是不确定这个人的姓氏，我们可以进行如下检索：

```mysql
EXPLAIN SELECT * FROM people
WHERE zipcode='000001'
AND lastname LIKE '张'
AND address LIKE'%北京市%';
```

执行查看SQL的查询计划，Extra中显示了Using index condition,这表示使用了索引下推。另外，Using where表示条件中包含需要过滤的非索引列的数据，即address LIKE'%北京市%'这个条件并不是索列，需要在服务端过滤掉。

这个表中存在两个索引，分别是：

![image-20220331134528782](https://zhangyuyetypora.oss-cn-guangzhou.aliyuncs.com/typora-user-images/image-20220331134528782.png)



### 10.4 ICP的使用条件

- 如果表访问的类型为range、ref、eq_ref和ref_or_null可以使用lCP
- ICP可以用于InnoDB和MyISAM表，包括分区表InnoDB和MyISAM表
- 对于InnoDB表，ICP仅用于二级索引。ICP的目标是减少全行读取次数，从而减少I/O操作。
- 当SQL使用覆盖索引时，不支持CP。因为这种情况下使用ICP不会减少I/O。
- 相关子查询的条件不能使用ICP

## 11.其它查询优化策略

### 11.1 EXISTS和IN的区分

问题：

不太理解哪种情况下应该使用EXISTS,哪种情况应该用IN。选择的标准是看能否使用表的索引吗？

回答：

索引是个前提，其实选择与否还是要看表的大小。你可以将选择的标准理解为**小表驱动大表**。在这种方式下效率是最高的。

```mysql
SELECT * FROM A WHERE cc IN (SELECT cc FROM B)

SELECT * FROM A WHERE cc EXISTS (SELECT cc FROM B WHERE A.cc = B.cc)
```

**哪个表小就用哪个表来驱动，A表小就用EXISTS,B表小就用IN。**

### 11.2 COUNT(*)与COUNT(具体字段)效率

问：在MySQL中统计数据表的行数，可以使用三种方式：SELECT C0UNT(*)、SELECT COUNT(1)和SELECTC0UNT(具体字段)，使用这三者之间的查询效率是怎样的？

答：

前提：如果你要统计的是某个字段的非空数据行数，则另当别论，毕竟比较执行效率的前提是结果一样才可以。

**环节1：**COUNT( * )和COUNT(1)都是对所有结果进行COUNT,COUNT(*)和COUNT(1)本质上并没有区别（二者执行时间可能略有差别，不过你还是可以把它俩的执行效率看成是相等的)。如果有WHERE子句，则是对所有符合筛选条件的数据行进行统计；如果没有WHERE子句，则是对数据表的数据行数进行统计。

**环节2：**如果是MyISAM存储引擎，统计数据表的行数只需要O(1)的复杂度，这是因为每张MyISAM的数据表都有一个meta信息存储了row_count值，而一致性则由表级锁来保证。

如果是InnoDB存储引擎，因为InnoDB支持事务，采用行级锁和MVCC机制，所以无法像MylSAM一样维护一个row_count变量，因此需要采用扫描全表，是O(n)的复杂度，进行循环+计数的方式来完成统计。

**环节3：**在InnoDB引擎中，如果采用COUNT(具体字段)来统计数据行数，要尽量采用二级索引。因为主键采用的索引是聚簇索引，聚簇索引包含的信息多，明显会大于二级索引（非聚簇索）。对于COUNT(*)和C0UNT(1)来说，它们不需要查我具体的行，只是统计行数，系统会自动采用占用空间更小的二级索来进行统计。

如果有多个二级索引，会使用key_len小的二级索引进行扫描。当没有二级索的时候，才会采用主键索引来进行统计。

### 11.3 关于SELECT(*)

在表查询中，建议明确字段，不要使用 * 作为查询的字段列表，推荐使用$ELECT<字段列表>查询。原因：

①MySQL在解析的过程中，会通过**查询数据字典**将"*"按序转换成所有列名，这会大大的耗费资源和时间。

②无法使用**覆盖索引**

### 11.4 LIMIT 1对优化的影响

针对的是会扫描全表的SQL语句，如果你可以确定结果集只有一条，那么加上LIMIT 1的时候，当找到一条结果的时候就不会继续扫描了，这样会加快查询速度。

如果数据表已经对字段建立了唯一索引，那么可以通过索引进行查询，不会全表扫描的话，就不需要加上LIMIT 1了。

### 12.5多使用COMMIT

只要有可能，在程序中尽量多使用COMMIT,这样程序的性能得到提高，需求也会因为COMMIT所释放的资源而减少。

COMMIT所释放的资源：

- 回滚段上用于恢复数据的信息
- 被程序语句获得的锁
- redo/undo log buffer中的空间
- 管理上述3种资源中的内部花费

## 13.淘宝数据库，主键如何设计的？

聊一个实际问题：淘宝的数据库，主键是如何设计的？

某些错的离谱的答案还在网上年复一年的流传着，甚至还成为了所谓的MySQL军规。其中，一个最明显的错误就是关于MySQL的主键设计。

大部分人的回答如此自信：用8字节的BIGINT做主键，而不要用INT。错！

这样的回答，只站在了数据库这一层，而没有**从业务的角度**思考主键。主键就是一个自增吗？站在2022年的新年档口，用自增做主键，架构设计上可能连**及格都拿不到**。

### 13.1自增ID的问题

自增ID做主键，简单易懂，几乎所有数据库都支持自增类型，只是实现上各自有所不同而已。自增ID除了简单，其他都是缺点，总体来看存在以下几方面的问题：

**1.可靠性不高**

存在自增ID回溯的问题，这个问题直到最新版本的MySQL8.0才修复。

**2.安全性不高**

对外暴露的接口可以非常容易猜测对应的信息。比如：User/1/这样的接口，可以非常容易猜测用户id的值为多少，总用户数量有多少，也可以非常容易地通过接口进行数据的爬取。

**3.性能差**

自增ID的性能较差，需要在数据库服务器端生成。

**4.交互多**

业务还需要额外执行一次类似last_insert_id()的函数才能知道钢刚才插入的自增值，这需要多一次的网络交互。在海量并发的系统中，多1条SQL,就多一次性能上的开销。

**5.局部唯一性**

最重要的一点，自增ID是局部唯一，只在当前数据库实例中唯一，而不是全局唯一，在任意服务器间都是唯一的。对于目前分布式系统来说，这简直就是噩梦。

### 13.2业务字段做主键

为了能够唯一地标识一个会员的信息，需要为会员信息表设置一个主键。那么，怎么为这个表设置主键，才能达到我们理想的目标呢？这里我们考虑业务字段做主键。

表数据如下：

![image-20220331141152510](https://zhangyuyetypora.oss-cn-guangzhou.aliyuncs.com/typora-user-images/image-20220331141152510.png)

- 选择卡号(cardno)

	会员卡号(cardno)看起来比较合适，因为会员卡号不能为空，而且有唯一性，可以用来标识一条会员记录。

	不同的会员卡号对应不同的会员，字段“cardno”唯一地标识某一个会员。如果都是这样，会员卡号与会员一一对应，系统是可以正常运行的。

	但实际情况是，**会员卡号可能存在重复使用的情况。**比如，张三因为工作变动搬离了原来的地址，不再到商家的门店消费了（退还了会员卡），于是张三就不再是这个商家门店的会员了。但是，商家不想让这个会员卡空着就把卡号是“10000001”的会员卡发给了王五。

	从系统设计的角度看，这个变化只是修改了会员信息表中的卡号是“10000001”这个会员信息，并不会影响到数据一致性。也就是说，修改会员卡号是“10000001”的会员信息，系统的各个模块，都会获取到修改后的会员信息不会出现“有的模块获取到修改之前的会员信息，有的模块获取到修改后的会员信息，而导致系统内部数据不一致”的情况。因此，从**信息系统层面上看**是没问题的。

	但是从**使用系统的业务层面**来看，就有很大的问题了，会对商家造成影响。

- 选择会员电话或身份证号

	会员电话可以做主键吗？不行的。在实际操作中，手机号也存在被运营商收回，重新发给别人用的情况

- 那身份证号行不行呢？好像可以。因为身份证决不会重复，身份证号与一个人存在一一对应的关系。可问题是，身份证号属于个人隐私，顾客不一定愿意给你。要是强制要求会员必须登记身份证号，会把很多客人赶跑的。其实，客户电话也有这个问题，这也是我们在设计会员信息表的时候，允许身份证号和电话都为空的原因。

- **所以，建议尽量不要用跟业务有关的字段做主键。华竟，作为项目设计的技术人员，我们谁也无法预测在项目的整个生命周期中，哪个业务字段会因为项目的业务需求而有重复，或者重用之类的情况出现。**

> 经验：
>
> 刚开始使用MySOL时，很多人都很容易犯的错误是喜欢用业务字段做主键，想当然地认为了解业务需求，但实际情况往往出乎意料，而更改主键设置的成本非常高。

### 13.3淘宝的主键设计

在淘宝的电商业务中，订单服务是一个核心业务。请问，订单表的主键淘宝是如何设计的呢？是自增ID吗？

打开淘宝，看一下订单信息：

![image-20220331141817537](https://zhangyuyetypora.oss-cn-guangzhou.aliyuncs.com/typora-user-images/image-20220331141817537.png)

从上图可以发现，订单号不是自增D！我们详细看下上述4个订单号：

```mysql
1550672064762308113
1481195847180308113
1431156171142308113
1431146631521308113
```

订单号是19位的长度，且订单的最后5位都是一样的，都是08113。且订单号的前面14位部分是单调递增的。大胆猜测，淘宝的订单ID设计应该是：

```
订单ID=时间+去重字段+用户ID后6位尾号
```

这样的设计能做到全局唯一，且对分布式系统查询及其友好，

### 13.4推荐的主键设计

**非核心业务：**对应表的主键自增ID,如告警、日志、监控等信息。

**核心业务：**主键设计至少应该是全局唯一且是单调递增。全局唯一保证在各系统之间都是唯一的，单调递增是希望插入时不影响数据库性能。

这里推荐最简单的一种主键设计：UUID。

UUID的特点：

全局唯一，占用36字节，数据无序，插入性能差。

认识UUID:

- 为什么UUD是全局唯一的？
- 为什么UUID占用36个字节？
- 为什么UUID是无序的？

MySQL数据库的UUID组成如下所示：

```
UUID=时间+UUID版本(16字节)-时钟序列(4字节)-MAC地址(12字节)
```

我们以UUlD值e0ea12d4-6473-11eb-943c-00155dbaa39d举例：

![image-20220331142443352](https://zhangyuyetypora.oss-cn-guangzhou.aliyuncs.com/typora-user-images/image-20220331142443352.png)

**为什么UUID是全局唯一的？**

在UUID中时间部分占用60位，存储的类似TIMESTAMPI的时间戳，但表示的是从1582-10-1500：00：00.00到现在的100ns的计数。可以看到UUID存储的时间精度比TIMESTAMPE更高，时间维度发生重复的慨率降低到1/100ns。时钟序列是为了避免时钟被回拨导致产生时间重复的可能性。MAC地址用于全局唯一。

**为什么UUID占用36个字节？**

UUID根据字符串进行存储，设计时还带有无用"-"字符串，因此总共需要36个字节。

**为什么UUID是随机无序的呢？**

因为UUID核心的设计中，将时间低位放在最前面，而这部分的数据是一直在变化的，并且是无序。

**改造UUID**

若将时间高低位互换，则时间就是单调递增的了，也就变得单调递增了。MySQL8.0可以更换时间低位和时间高位的存储方式，这样UUID就是有序的UUID了。

MySQL8.0还解决了UUID存在的空间占用的问题，除去了UUID字符串中无意义的"-"字符串，并且将字符串用二进制类型保存，这样存储空间降低为了16字节。

可以通过MySQL8,o提供的uuid_to_bin函数实现上述功能，同样的，MySQL也提供了bin_to_uuid函数进行转化：

```mysql
SET @uuid = UUID();

SELECT @uuid,uuid_to_bin(@uuid),uuid_to_bin(@uuid,TRUE);
```

通过函数uuid_to_bin(@uuid,true)将UUID转化为有序UUID了。全局唯一+单调递增，这不就是我们想要的主键！

> 在当今的互联网环境中，非常不推荐自增D作为主键的数据库设计。更推荐类似有序UUID的全局唯一的实现。
>
> 另外在真实的业务系统中，主键还可以加入业务和系统属性，如用户的尾号，机房的信息等。这样的主键设计就更为考验架构师的水平了。

**如果不是MySQL8.0肿么办？**

手动赋值字段做主键！

比如，设计各个分店的会员表的主键，因为如果每台机器各自产生的数据需要合并，就可能会出现主键重复的问题。

可以在总部MySQL数据库中，有一个管理信息表，在这个表中添加一个字段，专门用来记录当前会员编号的最大值。

